'use client';

import ErrorToast from '@/components/ErrorToast';
import locationTracker from '@/hooks/locationTracker';
import { OCRResponse } from '@/types/ocr';
import LABELS from '@app-datasets/coco/classes.json';
import { useQuery } from '@tanstack/react-query';
import * as cocoSsd from '@tensorflow-models/coco-ssd';
import * as tf from '@tensorflow/tfjs';
import '@tensorflow/tfjs-backend-webgl';
import { useRouter } from 'next/navigation';
import { useCallback, useEffect, useRef, useState } from 'react';
import Webcam from 'react-webcam';
import { BusArrivalResult, getBusArrival } from '../api/getBusArrival';
import { getBusNumber } from '../api/userUtils';

export default function Camera() {
  const router = useRouter();
  const [hasPermission, setHasPermission] = useState<boolean | null>(null);
  const webcamRef = useRef<Webcam>(null);
  const captureInterval = useRef<NodeJS.Timeout | null>(null);
  const [showCanvas, setShowCanvas] = useState(true);
  const [isNightMode, setIsNightMode] = useState(true);
  const [showNoStopToast, setShowNoStopToast] = useState(false);

  const requestCameraPermission = () => {
    setHasPermission(null);

    navigator.mediaDevices
      .getUserMedia({ video: true })
      .then(() => setHasPermission(true))
      .catch(() => setHasPermission(false));
  };

  //ai ÏÉÅÌÉú Í¥ÄÎ¶¨ Î∞è Ï∞∏Ï°∞ Î≥ÄÏàò
  const modelRef = useRef<tf.GraphModel | null>(null); // useRefÎ°ú Ï∞∏Ï°∞ÌïòÍ≤å ÏàòÏ†ï
  const [model, setModel] = useState<tf.GraphModel | null>(null);
  const ZOO_MODEL = [{ name: 'yolov5', child: ['yolov5n', 'yolov5s'] }];
  const [modelName] = useState(ZOO_MODEL[0]);
  const [loading, setLoading] = useState(0);
  const [detectedBus, setDetectedBus] = useState<string | null>(null);
  const [isDetectedBusArriving, setIsDetectedBusArriving] = useState(false);
  const [showNotification, setShowNotification] = useState(false);

  const canvasRef = useRef<HTMLCanvasElement>(null);

  useEffect(() => {
    const initializeApp = async () => {
      if (!locationTracker.isTracking()) {
        console.log('ÏúÑÏπò Ï∂îÏ†Å ÏãúÏûë...');
        locationTracker.startTracking();
      }
    };

    initializeApp();

    return () => {
      if (captureInterval.current) {
        clearInterval(captureInterval.current);
      }
    };
  }, []);

  const { data: locationStatus } = useQuery({
    queryKey: ['locationStatus'],
    queryFn: async () => {
      try {
        if (locationTracker.hasNearbyBusStops()) {
          await getBusArrival();
          return true;
        }
        return false;
      } catch (error) {
        console.log('ÏúÑÏπò Ï†ïÎ≥¥ Ï§ÄÎπÑ Ï§ë...', error);
        throw error;
      }
    },
    refetchInterval: (data) => {
      return data ? false : 3000;
    },
    retry: (failureCount) => {
      return failureCount < 20;
    },
    retryDelay: 3000,
    enabled: true,
  });

  const { data: busArrivalData } = useQuery<BusArrivalResult>({
    queryKey: ['busArrivals'],
    queryFn: getBusArrival,
    refetchInterval: 30000,
    enabled: true,
    retry: (failureCount) => {
      return failureCount < 10;
    },
    retryDelay: 1000,
    staleTime: 0,
    gcTime: 0,
  });

  const expectedBuses = busArrivalData?.buses || [];
  const hasNearbyStops = busArrivalData?.hasNearbyStops ?? false;
  const isRegisteredBusArriving = busArrivalData?.isRegisteredBusArriving ?? false;

  console.log('üîÑ Query ÏÉÅÌÉú:', {
    locationStatus,
    hasNearbyBusStops: locationTracker.hasNearbyBusStops(),
    busArrivalData,
    expectedBuses,
    hasNearbyStops,
    isRegisteredBusArriving,
  });

  //ai Î™®Îç∏ Î°úÎî© Ìï®Ïàò
  useEffect(() => {
    let isMounted = true;
    let loadedModel: tf.GraphModel | null = null;

    const loadModel = async () => {
      try {
        console.log('Starting model load...');
        // Use relative path for model
        const modelPath = `/model/${modelName.name}/${modelName.child[1]}/model.json`;
        console.log('Model path:', modelPath);

        // Check if model files exist
        try {
          const response = await fetch(modelPath);
          if (!response.ok) {
            throw new Error(`Model file not found: ${response.status}`);
          }
          console.log('Model file exists, starting to load...');
        } catch (error) {
          console.error('Model file check failed:', error);
          throw error;
        }

        // Dispose previous model if exists
        if (modelRef.current) {
          // ÏàòÏ†ï: model ÎåÄÏã† modelRef.current ÏÇ¨Ïö©
          console.log('Disposing previous model...');
          modelRef.current.dispose();
        }

        // Set loading state to indicate start
        if (isMounted) {
          setLoading(0.1);
        }

        loadedModel = await tf.loadGraphModel(modelPath, {
          onProgress: (fractions) => {
            console.log('Loading progress:', fractions);
            if (isMounted) {
              setLoading(fractions);
            }
          },
        });

        if (!loadedModel) {
          throw new Error('Model loading failed');
        }

        if (isMounted) {
          console.log('Model loaded, warming up...');
          const shape = loadedModel.inputs[0]?.shape || [1, 640, 640, 3];
          console.log('Model input shape:', shape);

          const dummy = tf.ones(shape);
          console.log('Running warmup inference...');
          const res = await loadedModel.executeAsync(dummy);

          // clear memory
          tf.dispose(res);
          tf.dispose(dummy);

          // save to both ref and state
          modelRef.current = loadedModel; // Î™®Îç∏ÏùÑ refÏóê Ï†ÄÏû•
          setModel(loadedModel); // Î™®Îç∏ÏùÑ stateÏóêÎèÑ Ï†ÄÏû•
          setLoading(1);
          console.log('Model ready');
        }
      } catch (error) {
        console.error('Error loading model:', error);
        if (isMounted) {
          modelRef.current = null; // ÏóêÎü¨ Ïãú refÎèÑ Ï¥àÍ∏∞Ìôî
          setModel(null);
          setLoading(0);
        }
      }
    };

    // Load model immediately
    loadModel();

    return () => {
      isMounted = false;
      if (loadedModel) {
        console.log('Cleaning up model...');
        loadedModel.dispose();
      }
    };
  }, [modelName]);

  // MobileNet SSD Î™®Îç∏ Î°úÎî©
  const [ssdModel, setSsdModel] = useState<cocoSsd.ObjectDetection | null>(null);
  const [ssdLoading, setSsdLoading] = useState(0);
  const ssdModelRef = useRef<cocoSsd.ObjectDetection | null>(null); // ref Ï∂îÍ∞Ä

  // MobileNet SSD Î™®Îç∏ Î°úÎî©
  useEffect(() => {
    let isMounted = true;

    const loadSsdModel = async () => {
      try {
        console.log('Starting MobileNet SSD model load...');
        setSsdLoading(0.1);

        const model = await cocoSsd.load({
          base: 'mobilenet_v2',
        });
        setSsdLoading(0.5);

        if (isMounted) {
          setSsdModel(model);
          ssdModelRef.current = model; // refÏóêÎèÑ Î™®Îç∏ Ï†ÄÏû•
          setSsdLoading(1);
          console.log('MobileNet SSD model ready');
        }
      } catch (error) {
        console.error('Error loading MobileNet SSD model:', error);
        if (isMounted) {
          setSsdModel(null);
          ssdModelRef.current = null; // refÎèÑ Ï¥àÍ∏∞Ìôî
          setSsdLoading(0);
        }
      }
    };

    loadSsdModel();

    return () => {
      isMounted = false;
      // cleanup
      if (ssdModelRef.current) {
        ssdModelRef.current = null;
      }
    };
  }, []);

  // Ïó¨Í∏∞ÏóêÏÑú Ïù¥ÎØ∏ÏßÄÎ•º Ï≤òÎ¶¨ÌïòÎ©¥ Îê† Í≤É Í∞ôÏïÑÏöî
  const sendImageToServer = async (imageData: string) => {
    if (imageData) {
      // Î©îÎ™®Î¶¨ Ï†ïÎ¶¨
      tf.engine().startScope();
      try {
        if (isNightMode) {
          await doPredictFrame(imageData); // yolov5n Î™®Îç∏ ÏÇ¨Ïö©
        } else {
          await doPredictFrame2(imageData); // mobilenet ssd Î™®Îç∏ ÏÇ¨Ïö©
        }
      } finally {
        // Î©îÎ™®Î¶¨ Ï†ïÎ¶¨
        tf.disposeVariables();
        tf.engine().endScope();
      }
    }
  };

  const doPredictFrame = async (imageData: string) => {
    const modelToUse = modelRef.current || model;

    if (!modelToUse) {
      console.log('Model not loaded');
      return;
    }

    try {
      // Create a temporary image element to load the screenshot
      const img = new Image();
      img.src = imageData;

      await new Promise((resolve) => {
        img.onload = resolve;
      });

      // Set canvas size to match image
      if (canvasRef.current) {
        canvasRef.current.width = img.width;
        canvasRef.current.height = img.height;
      }

      // get width and height from model's shape for resizing image
      const inputShape = modelToUse.inputs[0]?.shape;
      if (!inputShape) {
        console.log('No input shape found');
        return;
      }
      const [modelWidth, modelHeight] = inputShape.slice(1, 3);

      // pre-processing frame
      const input = tf.tidy(() => {
        const frameTensor = tf.browser.fromPixels(img);
        return tf.image
          .resizeBilinear(frameTensor, [modelWidth, modelHeight])
          .div(255.0)
          .expandDims(0);
      });

      // predicting...
      console.log('Running YOLOv5 prediction...');
      const res = await modelToUse.executeAsync(input);
      if (!Array.isArray(res)) {
        console.log('Model output is not an array');
        return;
      }

      const [boxes, scores, classes] = res as [tf.Tensor, tf.Tensor, tf.Tensor];
      const boxesData = Array.from(boxes.dataSync());
      const scoresData = Array.from(scores.dataSync());
      const classesData = Array.from(classes.dataSync());

      // build the predictions data
      await renderPrediction(boxesData, scoresData, classesData);

      // clear memory
      tf.dispose([boxes, scores, classes, input]);
    } catch (error) {
      console.error('Error in YOLOv5 prediction:', error);
    }
  };

  const renderPrediction = async (
    boxesData: number[],
    scoresData: number[],
    classesData: number[],
  ) => {
    if (!canvasRef.current || !webcamRef.current) return;

    const ctx = canvasRef.current.getContext('2d');
    if (!ctx) return;

    // clean canvas
    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);

    const font = '16px sans-serif';
    ctx.font = font;
    ctx.textBaseline = 'top';

    const processBusPromises: Promise<void>[] = [];
    let busProcessed = 0; // Î≤ÑÏä§ Ï≤òÎ¶¨ Í∞úÏàò

    for (let i = 0; i < scoresData.length; ++i) {
      const klass = LABELS[classesData[i]];
      const score = (scoresData[i] * 100).toFixed(1);

      // Only process if the score is above 40%
      if (parseFloat(score) < 30) continue;

      let [x1, y1, x2, y2] = boxesData.slice(i * 4, (i + 1) * 4);
      x1 *= canvasRef.current.width;
      x2 *= canvasRef.current.width;
      y1 *= canvasRef.current.height;
      y2 *= canvasRef.current.height;
      const width = x2 - x1;
      const height = y2 - y1;

      if (klass === 'bus') {
        // draw the bounding box
        ctx.strokeStyle = '#C53030';
        ctx.lineWidth = 2;
        ctx.strokeRect(x1, y1, width, height);

        const label = klass + ' - ' + score + '%';
        const textWidth = ctx.measureText(label).width;
        const textHeight = parseInt(font, 10); // base 10

        // draw the label background
        ctx.fillStyle = '#C53030';
        ctx.fillRect(x1 - 1, y1 - (textHeight + 4), textWidth + 6, textHeight + 4);

        // draw the label text
        ctx.fillStyle = '#FFFFFF';
        ctx.fillText(label, x1 + 2, y1 - (textHeight + 2));

        // Create a new canvas for the cropped image
        const cropCanvas = document.createElement('canvas');
        cropCanvas.width = width;
        cropCanvas.height = height;
        const cropCtx = cropCanvas.getContext('2d');
        if (!cropCtx) return;

        if (busProcessed >= 4) continue; // 4Í∞úÍπåÏßÄÎßå Ï≤òÎ¶¨
        busProcessed++;

        // Get the current frame from webcam
        const currentFrame = webcamRef.current.getScreenshot();
        if (!currentFrame) return;

        // Create an image from the current frame
        const frameImg = new Image();
        frameImg.src = currentFrame;

        // Wait for the image to load
        const promise = new Promise<void>((resolve) => {
          frameImg.onload = () => {
            const cropCanvas = document.createElement('canvas');
            cropCanvas.width = width;
            cropCanvas.height = height;
            const cropCtx = cropCanvas.getContext('2d');
            if (!cropCtx) return resolve();

            // Convert to data URL
            cropCtx.drawImage(frameImg, x1, y1, width, height, 0, 0, width, height);

            // Convert to data URL
            const croppedImage = cropCanvas.toDataURL('image/jpeg');

            // Ïù¥ÎØ∏ÏßÄ Ï†ÄÏû• Î∞è OCR Ï≤òÎ¶¨
            saveAndProcessBusImage(croppedImage);
          };
        });

        processBusPromises.push(promise);
      }
    }

    await Promise.all(processBusPromises);
  };

  const doPredictFrame2 = async (imageData: string) => {
    const ssdModelToUse = ssdModelRef.current || ssdModel;

    if (!ssdModelToUse) {
      console.log('SSD Model not loaded');
      return;
    }

    try {
      // Create a temporary image element to load the screenshot
      const img = new Image();
      img.src = imageData;

      await new Promise((resolve, reject) => {
        img.onload = resolve;
        img.onerror = reject;
      });

      // Set canvas size to match image
      if (canvasRef.current) {
        canvasRef.current.width = img.width;
        canvasRef.current.height = img.height;
      }

      // MobileNet SSD Î™®Îç∏ ÏÇ¨Ïö©
      console.log('Running SSD prediction...');
      const predictions = await ssdModelToUse.detect(img);

      // SSD ÏòàÏ∏° Í≤∞Í≥ºÎ•º Ï≤òÎ¶¨
      const boxesData: number[] = [];
      const scoresData: number[] = [];
      const classesData: number[] = [];

      predictions.forEach((prediction) => {
        const [x, y, width, height] = prediction.bbox;
        const normalizedX1 = x / img.width;
        const normalizedY1 = y / img.height;
        const normalizedX2 = (x + width) / img.width;
        const normalizedY2 = (y + height) / img.height;

        boxesData.push(normalizedX1, normalizedY1, normalizedX2, normalizedY2);
        scoresData.push(prediction.score);
        const classId = prediction.class === 'bus' ? 5 : -1;
        classesData.push(classId);
      });

      // Î≥ÄÌôòÎêú Îç∞Ïù¥ÌÑ∞Î°ú ÏòàÏ∏° Í≤∞Í≥º Î†åÎçîÎßÅ
      await renderPrediction2(boxesData, scoresData, classesData, img);
    } catch (error) {
      console.error('Error in SSD prediction:', error);
    }
  };

  const renderPrediction2 = async (
    boxesData: number[],
    scoresData: number[],
    classesData: number[],
    sourceImg: HTMLImageElement, // Ï∂îÍ∞Ä: ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄ Ï∞∏Ï°∞
  ) => {
    if (!canvasRef.current) {
      console.log('Canvas ref not available');
      return;
    }

    const ctx = canvasRef.current.getContext('2d');
    if (!ctx) {
      console.log('Canvas context not available');
      return;
    }

    // clean canvas
    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);

    const font = '16px sans-serif';
    ctx.font = font;
    ctx.textBaseline = 'top';

    const processBusPromises: Promise<void>[] = [];
    let busProcessed = 0;

    for (let i = 0; i < scoresData.length; ++i) {
      const klass = LABELS[classesData[i]];
      const score = (scoresData[i] * 100).toFixed(1);

      // Only process if the score is above 40%
      if (parseFloat(score) < 40) continue;

      // Ï†ïÍ∑úÌôîÎêú Ï¢åÌëúÎ•º Ïã§Ï†ú Ï∫îÎ≤ÑÏä§ Ï¢åÌëúÎ°ú Î≥ÄÌôò
      let [x1, y1, x2, y2] = boxesData.slice(i * 4, (i + 1) * 4);
      x1 *= canvasRef.current.width;
      x2 *= canvasRef.current.width;
      y1 *= canvasRef.current.height;
      y2 *= canvasRef.current.height;

      const width = x2 - x1;
      const height = y2 - y1;

      if (klass === 'bus' && busProcessed < 4) {
        // draw the bounding box
        ctx.strokeStyle = '#C53030';
        ctx.lineWidth = 2;
        ctx.strokeRect(x1, y1, width, height);

        const label = klass + ' - ' + score + '%';
        const textWidth = ctx.measureText(label).width;
        const textHeight = parseInt(font, 10);

        // draw the label background
        ctx.fillStyle = '#C53030';
        ctx.fillRect(x1 - 1, y1 - (textHeight + 4), textWidth + 6, textHeight + 4);

        // draw the label text
        ctx.fillStyle = '#FFFFFF';
        ctx.fillText(label, x1 + 2, y1 - (textHeight + 2));

        // If bus is detected, crop and save the image
        busProcessed++;

        const promise = new Promise<void>((resolve) => {
          const cropCanvas = document.createElement('canvas');
          cropCanvas.width = width;
          cropCanvas.height = height;
          const cropCtx = cropCanvas.getContext('2d');
          if (!cropCtx) return resolve();

          // sourceImgÎ•º ÏÇ¨Ïö©ÌïòÏó¨ ÌÅ¨Î°≠
          cropCtx.drawImage(sourceImg, x1, y1, width, height, 0, 0, width, height);
          const croppedImage = cropCanvas.toDataURL('image/jpeg');

          // OCR Ï≤òÎ¶¨
          saveAndProcessBusImage(croppedImage);

          resolve();
        });

        processBusPromises.push(promise);
      }
    }

    await Promise.all(processBusPromises);
  };
  // OCR API Ìò∏Ï∂ú Ìï®Ïàò
  const callOCRAPI = async (imageData: string): Promise<OCRResponse> => {
    try {
      // console.log('OCR API Ìò∏Ï∂ú ÏãúÏûë');
      const base64Data = imageData.split(',')[1];
      if (!base64Data) {
        console.error('Ïù¥ÎØ∏ÏßÄ Îç∞Ïù¥ÌÑ∞ Î≥ÄÌôò Ïã§Ìå®');
        throw new Error('Ïú†Ìö®ÌïòÏßÄ ÏïäÏùÄ Ïù¥ÎØ∏ÏßÄ Îç∞Ïù¥ÌÑ∞ÏûÖÎãàÎã§.');
      }

      // console.log('API ÏöîÏ≤≠ Ï†ÑÏÜ°');
      const response = await fetch('/api/ocr', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          imageData: base64Data,
        }),
      });

      // console.log('API ÏùëÎãµ ÏàòÏã†:', response.status);

      // ÏùëÎãµ ÏÉÅÌÉú ÌôïÏù∏
      if (!response.ok) {
        let errorMessage = 'API Ìò∏Ï∂ú Ïã§Ìå®';
        try {
          const errorData = await response.json();
          console.error('API ÏóêÎü¨ ÏùëÎãµ:', errorData);
          errorMessage = errorData.message || response.statusText;
        } catch (e) {
          console.error('ÏóêÎü¨ ÏùëÎãµ ÌååÏã± Ïã§Ìå®:', e);
          errorMessage = response.statusText;
        }
        throw new Error(errorMessage);
      }

      // ÏÑ±Í≥µ ÏùëÎãµÏùÑ JSONÏúºÎ°ú ÌååÏã±
      let result;
      try {
        result = (await response.json()) as OCRResponse;
        // console.log('OCR Í≤∞Í≥º ÏàòÏã†:', result);
      } catch (e) {
        console.error('ÏùëÎãµ ÌååÏã± ÏóêÎü¨:', e);
        throw new Error('API ÏùëÎãµÏùÑ ÌååÏã±Ìï† Ïàò ÏóÜÏäµÎãàÎã§.');
      }

      // OCR Í≤∞Í≥º Í≤ÄÏ¶ù
      if (!result.images || !result.images[0] || !result.images[0].fields) {
        console.error('ÏûòÎ™ªÎêú OCR Í≤∞Í≥º ÌòïÏãù:', result);
        throw new Error('OCR Í≤∞Í≥º ÌòïÏãùÏù¥ Ïò¨Î∞îÎ•¥ÏßÄ ÏïäÏäµÎãàÎã§.');
      }

      return result;
    } catch (error) {
      console.error('OCR API ÏóêÎü¨:', error);
      if (error instanceof Error) {
        console.error('ÏóêÎü¨ ÏÉÅÏÑ∏:', {
          message: error.message,
          stack: error.stack,
        });
      }
      throw error;
    }
  };

  // ÏßÑÏßú 3Î∞ïÏûê Îß§Ïπ≠ Ìï®Ïàò - OCR + APIÎ∞∞Ïó¥ + ÏûÖÎ†•ÌïúÎ≤ÑÏä§Î≤àÌò∏
  const checkBusMatch = (detectedBusNumber: string) => {
    console.log('=== 3Î∞ïÏûê Î≤ÑÏä§ Îß§Ïπ≠ Ï≤¥ÌÅ¨ ÏãúÏûë ===');
    console.log(`OCR Í∞êÏßÄÎêú Î≤ÑÏä§: "${detectedBusNumber}"`);

    // Ï°∞Í±¥ 1: ÏÇ¨Ïö©ÏûêÍ∞Ä ÏûÖÎ†•Ìï¥Îëî Î≤ÑÏä§ Î≤àÌò∏Í∞Ä ÏûàÏñ¥Ïïº Ìï®
    const userInputBusNumber = getBusNumber();
    console.log(`ÏÇ¨Ïö©Ïûê ÏûÖÎ†• Î≤ÑÏä§ Î≤àÌò∏: "${userInputBusNumber}"`);

    if (!userInputBusNumber) {
      console.log('‚ùå ÏÇ¨Ïö©ÏûêÍ∞Ä ÏûÖÎ†•Ìïú Î≤ÑÏä§ Î≤àÌò∏Í∞Ä ÏóÜÏäµÎãàÎã§');
      return false;
    }

    // Ï°∞Í±¥ 2: isRegisteredBusArrivingÏù¥ trueÏó¨Ïïº Ìï® (Îì±Î°ùÌïú Î≤ÑÏä§Í∞Ä Ïã§Ï†ú ÎèÑÏ∞© ÏòàÏ†ï)
    console.log(`Îì±Î°ù Î≤ÑÏä§ ÎèÑÏ∞© ÏòàÏ†ï ÏÉÅÌÉú: ${isRegisteredBusArriving}`);

    if (!isRegisteredBusArriving) {
      console.log('‚ùå Îì±Î°ùÌïú Î≤ÑÏä§Í∞Ä ÌòÑÏû¨ ÎèÑÏ∞© ÏòàÏ†ïÏù¥ ÏïÑÎãôÎãàÎã§');
      return false;
    }

    // Ï°∞Í±¥ 3: APIÏóêÏÑú Î∞õÏùÄ ÎèÑÏ∞© ÏòàÏ†ï Î≤ÑÏä§ Î∞∞Ïó¥Ïóê Ìï¥Îãπ Î≤ÑÏä§Í∞Ä ÏûàÏñ¥Ïïº Ìï®
    console.log(`API ÎèÑÏ∞© ÏòàÏ†ï Î≤ÑÏä§ Î™©Î°ù:`, expectedBuses);

    if (!expectedBuses || expectedBuses.length === 0) {
      console.log('‚ùå API ÎèÑÏ∞© ÏòàÏ†ï Î≤ÑÏä§ Î™©Î°ùÏù¥ ÎπÑÏñ¥ÏûàÏäµÎãàÎã§');
      return false;
    }

    const detectedStr = String(detectedBusNumber).trim();
    const userInputStr = String(userInputBusNumber).trim();

    // Ï°∞Í±¥ 4: OCR Í≤∞Í≥º === ÏÇ¨Ïö©Ïûê ÏûÖÎ†• Î≤ÑÏä§ Î≤àÌò∏
    console.log(`OCR "${detectedStr}" vs ÏÇ¨Ïö©ÏûêÏûÖÎ†• "${userInputStr}"`);

    if (detectedStr !== userInputStr) {
      console.log(`‚ùå OCR Í≤∞Í≥º(${detectedStr})ÏôÄ ÏÇ¨Ïö©Ïûê ÏûÖÎ†•(${userInputStr})Ïù¥ Îã§Î¶ÖÎãàÎã§`);
      return false;
    }

    // Ï°∞Í±¥ 5: API Î∞∞Ïó¥ÏóêÎèÑ Ìï¥Îãπ Î≤ÑÏä§Í∞Ä ÏûàÏñ¥Ïïº Ìï®
    const isInApiList = expectedBuses.some((bus) => String(bus.busNumber).trim() === detectedStr);

    console.log(`API Î∞∞Ïó¥Ïóê ${detectedStr} Ï°¥Ïû¨ Ïó¨Î∂Ä: ${isInApiList}`);

    if (!isInApiList) {
      console.log(`‚ùå API Î∞∞Ïó¥Ïóê ${detectedStr}Î≤à Î≤ÑÏä§Í∞Ä ÏóÜÏäµÎãàÎã§`);
      console.log(`API Î∞∞Ïó¥ Î≤ÑÏä§Îì§: [${expectedBuses.map((b) => b.busNumber).join(', ')}]`);
      return false;
    }

    console.log(`üéâüéâüéâ 3Î∞ïÏûê Î™®Îëê ÏùºÏπò! ÏôÑÎ≤ΩÌïú Îß§Ïπ≠!`);
    console.log(`‚úÖ OCR Í∞êÏßÄ: "${detectedStr}"`);
    console.log(`‚úÖ ÏÇ¨Ïö©Ïûê ÏûÖÎ†•: "${userInputStr}"`);
    console.log(`‚úÖ API Î∞∞Ïó¥Ïóê Ï°¥Ïû¨: ${isInApiList}`);
    console.log(`‚úÖ Îì±Î°ù Î≤ÑÏä§ ÎèÑÏ∞© ÏòàÏ†ï: ${isRegisteredBusArriving}`);
    console.log('=== 3Î∞ïÏûê Îß§Ïπ≠ ÏôÑÎ£å ===');
    return true;
  };

  // ÏàòÏ†ïÎêú Î≤ÑÏä§ Ïù¥ÎØ∏ÏßÄ Ï†ÄÏû• Î∞è OCR Ï≤òÎ¶¨
  const saveAndProcessBusImage = async (croppedImage: string) => {
    try {
      console.log('üñºÔ∏è Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨ ÏãúÏûë');
      const ocrResult = await callOCRAPI(croppedImage);

      if (ocrResult) {
        const busNumber = extractBusNumber(ocrResult);
        if (busNumber) {
          console.log('üéØ Î≤ÑÏä§ Î≤àÌò∏ Ïù∏Ïãù ÏÑ±Í≥µ:', busNumber);
          setDetectedBus(busNumber);

          console.log('üè† hasNearbyStops Ï≤¥ÌÅ¨:', hasNearbyStops);
          console.log('üöå expectedBuses:', expectedBuses);
          console.log('‚úÖ isRegisteredBusArriving:', isRegisteredBusArriving);
          console.log('üìä Ï†ÑÏ≤¥ busArrivalData:', busArrivalData);

          // Í∑ºÏ≤òÏóê Ï†ïÎ•òÏû•Ïù¥ ÏûàÎäî Í≤ΩÏö∞ÏóêÎßå Îß§Ïπ≠ Ï≤¥ÌÅ¨
          if (hasNearbyStops) {
            console.log('‚úÖ Ï†ïÎ•òÏû•Ïù¥ ÏûàÏùå - Îß§Ïπ≠ Ìï®Ïàò Ìò∏Ï∂ú');
            // 3Î∞ïÏûê Î™®Îëê Ï≤¥ÌÅ¨ÌïòÎäî Ìï®Ïàò Ìò∏Ï∂ú
            const isMatching = checkBusMatch(busNumber);
            console.log(`üîç Îß§Ïπ≠ Í≤∞Í≥º: ${isMatching}`);
            setIsDetectedBusArriving(isMatching);

            if (isMatching) {
              console.log('üéâ ÏïåÎ¶º ÌëúÏãú!');
              setShowNotification(true);
              setTimeout(() => setShowNotification(false), 5000);
            }
          } else {
            // Í∑ºÏ≤òÏóê Ï†ïÎ•òÏû•Ïù¥ ÏóÜÏúºÎ©¥ Îß§Ïπ≠ÌïòÏßÄ ÏïäÏùå
            console.log('‚ùå Í∑ºÏ≤òÏóê Ï†ïÎ•òÏû•Ïù¥ ÏóÜÏñ¥ Îß§Ïπ≠ÌïòÏßÄ ÏïäÏäµÎãàÎã§');
            setIsDetectedBusArriving(false);
          }
        } else {
          console.log('‚ùå Î≤ÑÏä§ Î≤àÌò∏Î•º Ï∞æÏùÑ Ïàò ÏóÜÏùå', ocrResult.images[0].fields);
        }
      }
    } catch (error) {
      console.error('Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨ Ï§ë ÏóêÎü¨:', error);
      if (error instanceof Error) {
        console.error('ÏóêÎü¨ ÏÉÅÏÑ∏:', {
          message: error.message,
          stack: error.stack,
        });
      }
    }
  };

  // Î≤ÑÏä§ Î≤àÌò∏ Ï∂îÏ∂ú Ìï®Ïàò
  const extractBusNumber = (ocrResult: OCRResponse): string | null => {
    try {
      const fields = ocrResult.images[0].fields;
      if (!fields || !fields.length) return null;
      console.log('fields Ï†ÑÏ≤¥ ÎÇ¥Ïö©: ', fields);
      //Î≤ÑÏä§ Î≤àÌò∏ Ìå®ÌÑ¥
      const busNumberPatterns = [
        /^\d{1,4}[-\s]?\d{1,4}$/, // ÏùºÎ∞ò Î≤ÑÏä§ (1, 1234-5678)
        /^[Í∞Ä-Ìû£]{1,4}\d{1,4}$/, // ÎßàÏùÑÎ≤ÑÏä§ (Í∞ïÎÇ®1)
        /^[A-Z]\d{1,4}$/, // Í≥µÌï≠Î≤ÑÏä§ (A1)
        /^[Í∞Ä-Ìû£]\d{1,4}[-\s]?\d{1,4}$/, // ÏßÄÏÑ†Î≤ÑÏä§ (Í∞ïÎÇ®1-1234) Îçî ÏûàÏúºÎ©¥ Ï∂îÌõÑ Ï∂îÍ∞Ä
      ];

      for (const field of fields) {
        const text = field.inferText.replace(/[\s¬∑‚Ä¢-]/g, '');
        for (const pattern of busNumberPatterns) {
          if (pattern.test(text)) {
            return text;
          }
        }
      }

      return null;
    } catch (error) {
      console.error('Î≤ÑÏä§ Î≤àÌò∏ Ï∂îÏ∂ú Ï§ë ÏóêÎü¨:', error);
      return null;
    }
  };

  const capture = useCallback(() => {
    if (!busArrivalData || !busArrivalData.hasNearbyStops) {
      console.log('busArrivalDataÍ∞Ä Ï§ÄÎπÑÎêòÏßÄ ÏïäÏùå, OCR Ïã§Ìñâ Î≥¥Î•ò');
      return;
    }
    const imageSrc = webcamRef.current?.getScreenshot();
    if (imageSrc) {
      sendImageToServer(imageSrc);
    }
  }, [isNightMode, busArrivalData]);

  const continuousCapture = useCallback(() => {
    if (captureInterval.current) {
      clearInterval(captureInterval.current);
    }

    captureInterval.current = setInterval(() => {
      capture();
    }, 1000);
  }, [capture, isNightMode]);

  useEffect(() => {
    requestCameraPermission();
    return () => {
      if (captureInterval.current) {
        clearInterval(captureInterval.current);
      }
    };
  }, []);

  useEffect(() => {
    if (hasPermission === true) {
      continuousCapture();
    }
  }, [hasPermission, continuousCapture, isNightMode]);

  useEffect(() => {
    if (hasNearbyStops === false) {
      setShowNoStopToast(true);
    }
  }, [hasNearbyStops]);

  // Î™®Îç∏ Î°úÎî© ÏÉÅÌÉúÏóê Îî∞Î•∏ UI Ï≤òÎ¶¨
  if (loading < 1 || ssdLoading < 1) {
    return (
      <div className="flex h-screen flex-col items-center justify-center">
        <div className="text-center">
          <p className="mb-4 text-lg font-medium">Î™®Îç∏ Î°úÎî© Ï§ë...</p>

          {/* YOLOv5 Î™®Îç∏ Î°úÎî© ÏÉÅÌÉú */}
          <div className="mb-4">
            <p className="mb-2 text-sm font-medium text-blue-600">YOLOv5 Î™®Îç∏</p>
            <div className="w-64 rounded-full bg-gray-200">
              <div
                className="h-2 rounded-full bg-blue-500 transition-all duration-300"
                style={{ width: `${loading * 100}%` }}
              />
            </div>
            <p className="mt-1 text-sm text-blue-600">{Math.round(loading * 100)}%</p>
          </div>

          {/* MobileNet SSD Î™®Îç∏ Î°úÎî© ÏÉÅÌÉú */}
          <div>
            <p className="mb-2 text-sm font-medium text-green-600">MobileNet SSD Î™®Îç∏</p>
            <div className="w-64 rounded-full bg-gray-200">
              <div
                className="h-2 rounded-full bg-green-500 transition-all duration-300"
                style={{ width: `${ssdLoading * 100}%` }}
              />
            </div>
            <p className="mt-1 text-sm text-green-600">{Math.round(ssdLoading * 100)}%</p>
          </div>
        </div>
      </div>
    );
  }

  if (hasPermission === null) {
    return (
      <div className="flex h-screen items-center justify-center">
        Ïπ¥Î©îÎùº Í∂åÌïúÏùÑ ÏöîÏ≤≠ Ï§ëÏûÖÎãàÎã§...
      </div>
    );
  }

  if (hasPermission === false) {
    return (
      <div className="flex h-screen flex-col items-center justify-center p-4 text-center">
        <p className="mb-4 text-red-500">Ïπ¥Î©îÎùº Ï†ëÍ∑º Í∂åÌïúÏù¥ Í±∞Î∂ÄÎêòÏóàÏäµÎãàÎã§.</p>

        <button
          onClick={requestCameraPermission}
          className="rounded-lg bg-blue-500 px-6 py-3 font-medium text-white transition-colors hover:bg-blue-600"
        >
          Ïπ¥Î©îÎùº Í∂åÌïú Îã§Ïãú ÏöîÏ≤≠ÌïòÍ∏∞
        </button>
      </div>
    );
  }

  return (
    <>
      {showNoStopToast && (
        <ErrorToast
          message="Ï£ºÎ≥ÄÏóê Ï†ïÎ•òÏû•Ïù¥ ÏóÜÏäµÎãàÎã§"
          description="Í∑ºÏ≤òÏóê Î≤ÑÏä§ Ï†ïÎ•òÏû•Ïù¥ ÏóÜÏäµÎãàÎã§"
          onClose={() => setShowNoStopToast(false)}
          isVisible={showNoStopToast}
        />
      )}
      <div className="flex h-screen flex-col bg-white">
        <div className="relative aspect-[3/4] max-h-[60vh] w-full overflow-hidden">
          <Webcam
            audio={false}
            ref={webcamRef}
            screenshotFormat="image/jpeg"
            videoConstraints={{
              facingMode: 'environment',
              aspectRatio: 4 / 3,
            }}
            className="h-full w-full object-cover"
            screenshotQuality={1}
          />

          {/* Ï∫îÎ≤ÑÏä§ ÌëúÏãú Ï°∞Í±¥Î∂Ä Î†åÎçîÎßÅ */}
          {showCanvas && (
            <canvas
              ref={canvasRef}
              className="absolute top-0 left-0 h-full w-full"
              style={{ zIndex: 1 }}
            />
          )}
          <div className="absolute top-4 right-4 left-4 flex justify-between" style={{ zIndex: 3 }}>
            <button
              onClick={() => setShowCanvas(!showCanvas)}
              className="bg-opacity-50 hover:bg-opacity-70 rounded-lg bg-black px-3 py-2 text-white transition-all"
            >
              {showCanvas ? 'Í∞êÏßÄ Ïà®Í∏∞Í∏∞' : 'Í∞êÏßÄ ÌëúÏãú'}
            </button>
            <button
              onClick={() => setIsNightMode(!isNightMode)}
              className="bg-opacity-50 hover:bg-opacity-70 rounded-lg bg-black px-3 py-2 text-white transition-all"
            >
              {isNightMode ? '‚òÄÔ∏è' : 'üåô'}
            </button>
          </div>

          {/* Î≤ÑÏä§ Î≤àÌò∏ Î≥ÄÍ≤Ω Î≤ÑÌäº */}
          <button
            onClick={() => router.push('/BusSearch')}
            className="absolute right-2 bottom-2 rounded-full bg-[#ffd700] px-3 py-1.5 text-sm font-medium text-[#353535] shadow transition-all hover:bg-yellow-400"
            style={{ zIndex: 3 }}
          >
            Î≤ÑÏä§Î≤àÌò∏ Îì±Î°ù
          </button>

          {/* ÏàòÏ†ïÎêú Bus Arrival Notification */}
          {showNotification && (
            <div
              className="absolute top-4 right-0 left-0 mx-auto w-4/5 rounded-lg bg-[#fff9db] p-4 text-center text-[#353535] shadow-lg"
              style={{ zIndex: 50 }}
            >
              <p className="text-lg font-bold">Îì±Î°ùÌïú Î≤ÑÏä§Í∞Ä ÎèÑÏ∞©ÌñàÏäµÎãàÎã§!</p>
              <p>{detectedBus}Î≤à Î≤ÑÏä§Í∞Ä Í≥ß ÎèÑÏ∞©Ìï©ÎãàÎã§</p>
            </div>
          )}
        </div>

        <div className="mt-4 p-4">
          {detectedBus && (
            <div
              className={`mb-4 rounded-full p-4 text-center ${
                isDetectedBusArriving ? 'bg-[#ffd700]' : 'bg-gray-100'
              }`}
            >
              <p className="text-7xl font-bold text-[#353535]">{detectedBus}</p>
            </div>
          )}

          {/* Expected bus arrivals */}
          <div className="mt-2 mb-4">
            <p className="mb-2 font-medium">ÎèÑÏ∞© ÏòàÏ†ï Î≤ÑÏä§</p>
            {hasNearbyStops ? (
              expectedBuses.length > 0 ? (
                <div>
                  <div className="mb-2 flex flex-wrap gap-2">
                    {expectedBuses.map((bus, index) => (
                      <span
                        key={index}
                        className="rounded-full bg-[#ffd700] px-3 py-1 text-sm font-semibold text-[#353535]"
                      >
                        {bus.busNumber}
                      </span>
                    ))}
                  </div>
                  {isRegisteredBusArriving ? (
                    <p className="text-sm font-medium text-green-600">
                      ‚úÖ Îì±Î°ùÌïú Î≤ÑÏä§Í∞Ä ÎèÑÏ∞© ÏòàÏ†ïÏûÖÎãàÎã§!
                    </p>
                  ) : (
                    <p className="text-sm text-gray-500">Îì±Î°ùÌïú Î≤ÑÏä§Îäî ÌòÑÏû¨ ÎèÑÏ∞© ÏòàÏ†ïÏù¥ ÏïÑÎãôÎãàÎã§</p>
                  )}
                </div>
              ) : (
                <p className="text-gray-500">ÎèÑÏ∞© ÏòàÏ†ï Î≤ÑÏä§Í∞Ä ÏóÜÏäµÎãàÎã§</p>
              )
            ) : (
              <p className="text-orange-500">Í∑ºÏ≤òÏóê Î≤ÑÏä§ Ï†ïÎ•òÏû•Ïù¥ ÏóÜÏäµÎãàÎã§</p>
            )}
          </div>

          {/* ÎîîÎ≤ÑÍπÖÏö© Ï†ïÎ≥¥ ÌëúÏãú (Í∞úÎ∞ú Ï§ëÏóêÎßå ÏÇ¨Ïö©) */}
          {/* <div className="mt-4 rounded bg-gray-100 p-2 text-xs text-gray-600">
            <p>üì± OCR Í∞êÏßÄ Î≤ÑÏä§: {detectedBus || 'ÏóÜÏùå'}</p>
            <p>üë§ ÏÇ¨Ïö©Ïûê ÏûÖÎ†• Î≤ÑÏä§: {getBusNumber() || 'ÏóÜÏùå'}</p>
            <p>üöå API ÎèÑÏ∞©ÏòàÏ†ï Î≤ÑÏä§: {expectedBuses.map((b) => b.busNumber).join(', ') || 'ÏóÜÏùå'}</p>
            <p>üè† Í∑ºÏ≤ò Ï†ïÎ•òÏû•: {hasNearbyStops ? 'ÏûàÏùå' : 'ÏóÜÏùå'}</p>
            <p>‚úÖ Îì±Î°ù Î≤ÑÏä§ ÎèÑÏ∞© ÏòàÏ†ï: {isRegisteredBusArriving ? 'Ïòà' : 'ÏïÑÎãàÏò§'}</p>
            <p>üéØ ÏµúÏ¢Ö Îß§Ïπ≠: {isDetectedBusArriving ? 'ÏÑ±Í≥µ' : 'Ïã§Ìå®'}</p>
          </div> */}
        </div>
      </div>
    </>
  );
}
